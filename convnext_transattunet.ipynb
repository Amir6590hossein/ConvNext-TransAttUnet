{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        \n",
    "        # Calculate valid groups for mid_channels\n",
    "        if mid_channels % 32 == 0: groups_mid = 32\n",
    "        elif mid_channels % 16 == 0: groups_mid = 16\n",
    "        elif mid_channels % 8 == 0: groups_mid = 8\n",
    "        else: groups_mid = 1\n",
    "        \n",
    "        # Calculate valid groups for out_channels\n",
    "        if out_channels % 32 == 0: groups_out = 32\n",
    "        elif out_channels % 16 == 0: groups_out = 16\n",
    "        elif out_channels % 8 == 0: groups_out = 8\n",
    "        else: groups_out = 1\n",
    "\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(groups_mid, mid_channels), \n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(groups_out, out_channels), \n",
    "        )\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            # Fix shortcut groups as well\n",
    "            if out_channels % 32 == 0: groups_sc = 32\n",
    "            elif out_channels % 16 == 0: groups_sc = 16\n",
    "            else: groups_sc = 1\n",
    "            \n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "                nn.GroupNorm(groups_sc, out_channels) # Fixed\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "        self.final_act = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.final_act(self.double_conv(x) + self.shortcut(x))\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelShuffleUp(nn.Module):\n",
    "    def __init__(self, deep_ch, skip_ch, out_ch):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Upsampling block using PixelShuffle (efficient sub-pixel convolution)\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(deep_ch, deep_ch * 4, kernel_size=1, bias=False),\n",
    "            nn.PixelShuffle(upscale_factor=2),\n",
    "            nn.GroupNorm(1, deep_ch), \n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # Convolution block for feature fusion after concatenation\n",
    "        self.conv = DoubleConv(deep_ch + skip_ch, out_ch)\n",
    "\n",
    "    def forward(self, x_deep, x_skip):\n",
    "        x_up = self.project(x_deep)\n",
    "        \n",
    "        # Handle spatial dimension mismatch via padding (crucial for U-Net)\n",
    "        diffY = x_skip.size()[2] - x_up.size()[2]\n",
    "        diffX = x_skip.size()[3] - x_up.size()[3]\n",
    "        \n",
    "        x_up = F.pad(x_up, [diffX // 2, diffX - diffX // 2,\n",
    "                            diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        # Concatenate skip connection and upsampled features\n",
    "        x_cat = torch.cat([x_skip, x_up], dim=1)\n",
    "        \n",
    "        return self.conv(x_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class PAM_Module(nn.Module):\n",
    "    \"\"\" Position Attention Module (GSA) \"\"\"\n",
    "    def __init__(self, in_dim):\n",
    "        super(PAM_Module, self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim // 8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim // 8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        m_batchsize, C, height, width = x.size()\n",
    "        proj_query = self.query_conv(x).view(m_batchsize, -1, width * height).permute(0, 2, 1)\n",
    "        proj_key = self.key_conv(x).view(m_batchsize, -1, width * height)\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "        attention = self.softmax(energy)\n",
    "        proj_value = self.value_conv(x).view(m_batchsize, -1, width * height)\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(m_batchsize, C, height, width)\n",
    "        out = self.gamma * out + x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSA_Block(nn.Module):\n",
    "    \"\"\"\n",
    "    Replaces original Transformer Self Attention with\n",
    "    Large Kernel Attention (LKA) - 2024/2025 SOTA method\n",
    "    \"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        # Local Context (5x5)\n",
    "        self.conv0 = nn.Conv2d(dim, dim, 5, padding=2, groups=dim)\n",
    "        # Long-range Context (7x7 dilated) -> Simulates Global Attention linearly\n",
    "        self.conv_spatial = nn.Conv2d(dim, dim, 7, stride=1, padding=9, groups=dim, dilation=3)\n",
    "        # Channel Mixing\n",
    "        self.conv1 = nn.Conv2d(dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.clone()\n",
    "        attn = self.conv0(x)\n",
    "        attn = self.conv_spatial(attn)\n",
    "        attn = self.conv1(attn)\n",
    "        return u * attn\n",
    "\n",
    "class SAA_Module(nn.Module):\n",
    "    \"\"\" Self-Aware Attention Module (Improved) \"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super(SAA_Module, self).__init__()\n",
    "        self.norm1 = nn.BatchNorm2d(dim)\n",
    "        self.tsa = TSA_Block(dim) # This is now the LKA-based block\n",
    "        self.norm2 = nn.BatchNorm2d(dim)\n",
    "\n",
    "        # Feed Forward Network (Standard in modern blocks)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim*4, 1),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(dim*4, dim, 1),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Residual connection 1 (Attention)\n",
    "        x = x + self.tsa(self.norm1(x))\n",
    "        # Residual connection 2 (FFN)\n",
    "        x = x + self.ffn(self.norm2(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAM_Module(nn.Module):\n",
    "    \"\"\" Channel Attention Module \"\"\"\n",
    "    def __init__(self, in_dim):\n",
    "        super(CAM_Module, self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        m_batchsize, C, height, width = x.size()\n",
    "        proj_query = x.view(m_batchsize, C, -1)\n",
    "        proj_key = x.view(m_batchsize, C, -1).permute(0, 2, 1)\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "        energy_new = torch.max(energy, -1, keepdim=True)[0].expand_as(energy) - energy\n",
    "        attention = self.softmax(energy_new)\n",
    "        proj_value = x.view(m_batchsize, C, -1)\n",
    "        out = torch.bmm(attention, proj_value)\n",
    "        out = out.view(m_batchsize, C, height, width)\n",
    "        out = self.gamma * out + x\n",
    "        return out\n",
    "\n",
    "\n",
    "class DANetBlock(nn.Module):\n",
    "    \"\"\" Dual Attention: Parallel PAM + CAM \"\"\"\n",
    "    def __init__(self, in_channels):\n",
    "        super(DANetBlock, self).__init__()\n",
    "        self.pam = PAM_Module(in_channels)  # spatial\n",
    "        self.cam = CAM_Module(in_channels)  # channel\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_pam = self.pam(x)\n",
    "        x_cam = self.cam(x)\n",
    "        return x_pam + x_cam  # fusion\n",
    "    \n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
    "            nn.GroupNorm(32, out_channels), # GroupNorm\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=6, dilation=6, bias=False),\n",
    "            nn.GroupNorm(32, out_channels), # GroupNorm\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=12, dilation=12, bias=False),\n",
    "            nn.GroupNorm(32, out_channels), # GroupNorm\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=18, dilation=18, bias=False),\n",
    "            nn.GroupNorm(32, out_channels), # GroupNorm\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        self.branch5 = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
    "            nn.GroupNorm(32, out_channels), # GroupNorm\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(out_channels * 5, out_channels, 1, bias=False),\n",
    "            nn.GroupNorm(32, out_channels), # GroupNorm\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, w = x.shape[2], x.shape[3]\n",
    "        b1 = self.branch1(x)\n",
    "        b2 = self.branch2(x)\n",
    "        b3 = self.branch3(x)\n",
    "        b4 = self.branch4(x)\n",
    "        b5 = F.interpolate(self.branch5(x), size=(h, w), mode='bilinear', align_corners=True)\n",
    "        out = torch.cat([b1, b2, b3, b4, b5], dim=1)\n",
    "        return self.bottleneck(out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttentionGate, self).__init__()\n",
    "        \n",
    "        if F_int % 32 == 0: groups = 32\n",
    "        elif F_int % 16 == 0: groups = 16\n",
    "        elif F_int % 8 == 0: groups = 8\n",
    "        else: groups = 1\n",
    "\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.GroupNorm(groups, F_int)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.GroupNorm(groups, F_int)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        \n",
    "        if g1.shape[2:] != x1.shape[2:]:\n",
    "            g1 = F.interpolate(g1, size=x1.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedTransAttUnet(nn.Module):\n",
    "    def __init__(self, n_classes=1, backbone_name='convnextv2_tiny.fcmae_ft_in22k_in1k', pretrained=True):\n",
    "        super(PretrainedTransAttUnet, self).__init__()\n",
    "        \n",
    "        self.encoder = timm.create_model(\n",
    "            backbone_name, \n",
    "            features_only=True, \n",
    "            pretrained=pretrained,\n",
    "            out_indices=(0, 1, 2, 3)  \n",
    "        )\n",
    "        \n",
    "        feature_channels = self.encoder.feature_info.channels()\n",
    "        c1, c2, c3, c4 = feature_channels \n",
    "        print(f\"Adaptive Channels: {feature_channels}\")\n",
    "\n",
    "        self.aspp = ASPP(in_channels=c4, out_channels=c4)\n",
    "        self.danet = DANetBlock(c4)\n",
    "        self.saa_bridge = SAA_Module(c4) \n",
    "\n",
    "        self.ag1 = AttentionGate(F_g=c4, F_l=c3, F_int=c3 // 2)\n",
    "        self.ag2 = AttentionGate(F_g=c3, F_l=c2, F_int=c2 // 2)\n",
    "        self.ag3 = AttentionGate(F_g=c2, F_l=c1, F_int=c1 // 2)\n",
    "\n",
    "        self.up1 = PixelShuffleUp(deep_ch=c4, skip_ch=c3, out_ch=c3) \n",
    "        \n",
    "        self.up2 = PixelShuffleUp(deep_ch=c3, skip_ch=c2, out_ch=c2)\n",
    "        \n",
    "        self.up3 = PixelShuffleUp(deep_ch=c2, skip_ch=c1, out_ch=c1)\n",
    "\n",
    "        self.outc_final = OutConv(c1, n_classes)\n",
    "        self.outc_up1 = OutConv(c3, n_classes) \n",
    "        self.outc_up2 = OutConv(c2, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        features = self.encoder(x)\n",
    "        x1, x2, x3, x4 = features \n",
    "        \n",
    "        # Bridge\n",
    "        x_center = self.saa_bridge(self.danet(self.aspp(x4)))\n",
    "        \n",
    "        # Decoder Path\n",
    "        x3_ag = self.ag1(g=x_center, x=x3)\n",
    "        d1 = self.up1(x_center, x3_ag)\n",
    "        \n",
    "        x2_ag = self.ag2(g=d1, x=x2)\n",
    "        d2 = self.up2(d1, x2_ag)\n",
    "        \n",
    "        x1_ag = self.ag3(g=d2, x=x1)\n",
    "        d3 = self.up3(d2, x1_ag) \n",
    "\n",
    "        input_size = x.shape[2:]\n",
    "        \n",
    "        out_final = F.interpolate(self.outc_final(d3), size=input_size, mode='bilinear', align_corners=True)\n",
    "        out_d1 = F.interpolate(self.outc_up1(d1), size=input_size, mode='bilinear', align_corners=True)\n",
    "        out_d2 = F.interpolate(self.outc_up2(d2), size=input_size, mode='bilinear', align_corners=True)\n",
    "\n",
    "        return [out_final, out_d2, out_d1] "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
